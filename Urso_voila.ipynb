{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# !pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bear_types = 'grizzly','black','teddy'\n",
    "path = Path('ursos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not path.exists():\n",
    "    path.mkdir()\n",
    "    for o in bear_types:\n",
    "        dest = (path/o)\n",
    "        dest.mkdir(exist_ok=True)\n",
    "        results = search_images_bing(key, f'{o} bear')\n",
    "        download_images(dest, urls=results.attrgot('contentUrl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [Path('export.pkl')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path()\n",
    "path.ls(file_exts='.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need this file wherever you deploy your app to. For now, let's try to create a simple app within our notebook.\n",
    "\n",
    "When we use a model for getting predictions, instead of training, we call it *inference*. To create our inference learner from the exported file, we use `load_learner` (in this case, this isn't really necessary, since we already have a working `Learner` in our notebook; we're just doing it here so you can see the whole process end-to-end):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_inf = load_learner(path/'export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['black', 'grizzly', 'teddy']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_inf.dls.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65640e55b794e18a3dea36a9ea4e6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_output\n",
    "btn_upload = widgets.FileUpload()\n",
    "btn_upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "# For the book, we can't actually click an upload button, so we fake it\n",
    "btn_upload = SimpleNamespace(data = ['images/TesteUrsos/image7.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PILImage.create(btn_upload.data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320fabe8a6e14f668433a62a9d2f35f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_output\n",
    "out_pl = widgets.Output()\n",
    "out_pl.clear_output()\n",
    "with out_pl: display(img.to_thumb(128,128))\n",
    "out_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred,pred_idx,probs = learn_inf.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8330e2ddec4776a37db37db5a29329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Prediction: grizzly; Probability: 0.9992')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_output\n",
    "lbl_pred = widgets.Label()\n",
    "lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\n",
    "lbl_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac2c759e1894d7698a8e7e5f419d2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Classificação', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_output\n",
    "btn_run = widgets.Button(description='Classificação')\n",
    "btn_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also need a *click event handler*; that is, a function that will be called when it's pressed. We can just copy over the lines of code from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_classify(change):\n",
    "    img = PILImage.create(btn_upload.data[-1])\n",
    "    out_pl.clear_output()\n",
    "    with out_pl: display(img.to_thumb(128,128))\n",
    "    pred,pred_idx,probs = learn_inf.predict(img)\n",
    "    lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\n",
    "\n",
    "btn_run.on_click(on_click_classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test the button now by pressing it, and you should see the image and predictions update automatically!\n",
    "\n",
    "We can now put them all in a vertical box (`VBox`) to complete our GUI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Putting back btn_upload to a widget for next cell\n",
    "btn_upload = widgets.FileUpload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7964516d45b548ba8fda7adfc92a0c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Selecione seu urso!'), FileUpload(value={}, description='Upload'), Button(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_output\n",
    "VBox([widgets.Label('Selecione seu urso!'), \n",
    "      btn_upload, btn_run, out_pl, lbl_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting voila\n",
      "  Downloading voila-0.2.7-py3-none-any.whl (2.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5 MB 21.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nbconvert<7,>=6.0.0\n",
      "  Downloading nbconvert-6.0.7-py3-none-any.whl (552 kB)\n",
      "\u001b[K     |████████████████████████████████| 552 kB 88.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter-server<2.0.0,>=0.3.0\n",
      "  Downloading jupyter_server-1.4.1-py3-none-any.whl (241 kB)\n",
      "\u001b[K     |████████████████████████████████| 241 kB 74.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jupyter-client<7,>=6.1.3 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from voila) (6.1.7)\n",
      "Requirement already satisfied: nbclient<0.6,>=0.4.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from voila) (0.5.1)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (0.6.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (0.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (0.8.4)\n",
      "Requirement already satisfied: jinja2>=2.4 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (2.11.2)\n",
      "Requirement already satisfied: nbformat>=4.4 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (5.0.8)\n",
      "Requirement already satisfied: bleach in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (3.2.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (1.4.2)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (4.7.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (5.0.5)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (2.7.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (0.1.2)\n",
      "Requirement already satisfied: testpath in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (0.4.4)\n",
      "Requirement already satisfied: tornado>=6.1.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (6.1)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (0.9.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (0.9.0)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (1.5.0)\n",
      "Collecting anyio>=2.0.2\n",
      "  Downloading anyio-2.2.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 10.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyzmq>=17 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (20.0.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (0.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-client<7,>=6.1.3->voila) (2.8.1)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbclient<0.6,>=0.4.0->voila) (1.4.3)\n",
      "Requirement already satisfied: async-generator in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbclient<0.6,>=0.4.0->voila) (1.10)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jinja2>=2.4->nbconvert<7,>=6.0.0->voila) (1.1.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbformat>=4.4->nbconvert<7,>=6.0.0->voila) (3.2.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/envs/fastai/lib/python3.8/site-packages (from bleach->nbconvert<7,>=6.0.0->voila) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from bleach->nbconvert<7,>=6.0.0->voila) (1.15.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/fastai/lib/python3.8/site-packages (from bleach->nbconvert<7,>=6.0.0->voila) (20.4)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /opt/conda/envs/fastai/lib/python3.8/site-packages (from terminado>=0.8.3->jupyter-server<2.0.0,>=0.3.0->voila) (0.6.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from anyio>=2.0.2->jupyter-server<2.0.0,>=0.3.0->voila) (2.10)\n",
      "Collecting sniffio>=1.1\n",
      "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert<7,>=6.0.0->voila) (49.6.0.post20201009)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert<7,>=6.0.0->voila) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert<7,>=6.0.0->voila) (20.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from packaging->bleach->nbconvert<7,>=6.0.0->voila) (2.4.7)\n",
      "Installing collected packages: nbconvert, sniffio, anyio, jupyter-server, voila\n",
      "  Attempting uninstall: nbconvert\n",
      "    Found existing installation: nbconvert 5.6.1\n",
      "    Uninstalling nbconvert-5.6.1:\n",
      "      Successfully uninstalled nbconvert-5.6.1\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "nbdev 1.1.5 requires nbconvert<6, but you'll have nbconvert 6.0.7 which is incompatible.\u001b[0m\n",
      "Successfully installed anyio-2.2.0 jupyter-server-1.4.1 nbconvert-6.0.7 sniffio-1.2.0 voila-0.2.7\n",
      "Enabling: voila\n",
      "- Writing config: /opt/conda/envs/fastai/etc/jupyter\n",
      "    - Validating...\n",
      "      voila 0.2.7 \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!pip install voila\n",
    "!jupyter serverextension enable --sys-prefix voila "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have everything working in this Jupyter notebook, we can create our application. To do this, start a new notebook and add to it only the code needed to create and show the widgets that you need, and markdown for any text that you want to appear. Have a look at the *bear_classifier* notebook in the book's repo to see the simple notebook application we created.\n",
    "\n",
    "Next, install Voilà if you haven't already, by copying these lines into a notebook cell and executing it:\n",
    "\n",
    "    !pip install voila\n",
    "    !jupyter serverextension enable --sys-prefix voila\n",
    "\n",
    "Cells that begin with a `!` do not contain Python code, but instead contain code that is passed to your shell (bash, Windows PowerShell, etc.). If you are comfortable using the command line, which we'll discuss more later in this book, you can of course simply type these two lines (without the `!` prefix) directly into your terminal. In this case, the first line installs the `voila` library and application, and the second connects it to your existing Jupyter notebook.\n",
    "\n",
    "Voilà runs Jupyter notebooks just like the Jupyter notebook server you are using now does, but it also does something very important: it removes all of the cell inputs, and only shows output (including ipywidgets), along with your markdown cells. So what's left is a web application! To view your notebook as a Voilà web application, replace the word \"notebooks\" in your browser's URL with: \"voila/render\". You will see the same content as your notebook, but without any of the code cells.\n",
    "\n",
    "Of course, you don't need to use Voilà or ipywidgets. Your model is just a function you can call (`pred,pred_idx,probs = learn.predict(img)`), so you can use it with any framework, hosted on any platform. And you can take something you've prototyped in ipywidgets and Voilà and later convert it into a regular web application. We're showing you this approach in the book because we think it's a great way for data scientists and other folks that aren't web development experts to create applications from their models.\n",
    "\n",
    "We have our app, now let's deploy it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying your app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you now know, you need a GPU to train nearly any useful deep learning model. So, do you need a GPU to use that model in production? No! You almost certainly *do not need a GPU to serve your model in production*. There are a few reasons for this:\n",
    "\n",
    "- As we've seen, GPUs are only useful when they do lots of identical work in parallel. If you're doing (say) image classification, then you'll normally be classifying just one user's image at a time, and there isn't normally enough work to do in a single image to keep a GPU busy for long enough for it to be very efficient. So, a CPU will often be more cost-effective.\n",
    "- An alternative could be to wait for a few users to submit their images, and then batch them up and process them all at once on a GPU. But then you're asking your users to wait, rather than getting answers straight away! And you need a high-volume site for this to be workable. If you do need this functionality, you can use a tool such as Microsoft's [ONNX Runtime](https://github.com/microsoft/onnxruntime), or [AWS Sagemaker](https://aws.amazon.com/sagemaker/)\n",
    "- The complexities of dealing with GPU inference are significant. In particular, the GPU's memory will need careful manual management, and you'll need a careful queueing system to ensure you only process one batch at a time.\n",
    "- There's a lot more market competition in CPU than GPU servers, as a result of which there are much cheaper options available for CPU servers.\n",
    "\n",
    "Because of the complexity of GPU serving, many systems have sprung up to try to automate this. However, managing and running these systems is also complex, and generally requires compiling your model into a different form that's specialized for that system. It's typically preferable to avoid dealing with this complexity until/unless your app gets popular enough that it makes clear financial sense for you to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For at least the initial prototype of your application, and for any hobby projects that you want to show off, you can easily host them for free. The best place and the best way to do this will vary over time, so check the [book's website](https://book.fast.ai/) for the most up-to-date recommendations. As we're writing this book in early 2020 the simplest (and free!) approach is to use [Binder](https://mybinder.org/). To publish your web app on Binder, you follow these steps:\n",
    "\n",
    "1. Add your notebook to a [GitHub repository](http://github.com/).\n",
    "2. Paste the URL of that repo into Binder's URL, as shown in <<deploy-binder>>.\n",
    "3. Change the File dropdown to instead select URL.\n",
    "4. In the \"URL to open\" field, enter `/voila/render/name.ipynb` (replacing `name` with the name of for your notebook).\n",
    "5. Click the clickboard button at the bottom right to copyt the URL and paste it somewhere safe. \n",
    "6. Click Launch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Deploying to Binder\" width=\"800\" caption=\"Deploying to Binder\" id=\"deploy-binder\" src=\"images/att_00001.png\">"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Pièces jointes",
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
